{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807f7ca0-6fbb-4fa0-a2c9-2e9295937cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import data_loader. Will load images manually.\n",
      "OpenCV version: 4.12.0\n",
      "Numpy, os, glob, and sys imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys # 导入 sys 来修改路径\n",
    "\n",
    "# --- 关键的路径设置 ---\n",
    "# 告诉 Python 在哪里可以找到 utils 文件夹\n",
    "# ../ 是返回上一级 (即 COMP9517 根目录)\n",
    "utils_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "# 现在我们可以安全地从 utils 导入了\n",
    "try:\n",
    "    from utils.data_loader import load_data # 假设有这个函数\n",
    "    print(\"data_loader imported successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Could not import data_loader. Will load images manually.\")\n",
    "    load_data = None # 设置一个标记\n",
    "\n",
    "# 打印一下，确保导入成功\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(\"Numpy, os, glob, and sys imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78a93e7-9a39-42c5-8090-d8beb78fd4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功找到数据文件夹: E:\\comp9517_project\\data\\AgroPest-12\\train\\images\n",
      "Total training images found: 11502\n"
     ]
    }
   ],
   "source": [
    "# 1. 定义你的数据集的根目录\n",
    "#    (这个相对路径现在是正确的，从 features/ notebook 出发)\n",
    "DATASET_DIR = '../../data/AgroPest-12/'\n",
    "\n",
    "# 2. 定义训练集图像的路径\n",
    "TRAIN_IMAGE_DIR = os.path.join(DATASET_DIR, 'train', 'images')\n",
    "\n",
    "# 3. 检查路径是否存在\n",
    "if not os.path.exists(TRAIN_IMAGE_DIR):\n",
    "    print(f\"!!! 错误：找不到路径 !!!\")\n",
    "    print(f\"请检查这个路径是否正确: {os.path.abspath(TRAIN_IMAGE_DIR)}\")\n",
    "else:\n",
    "    print(f\"成功找到数据文件夹: {os.path.abspath(TRAIN_IMAGE_DIR)}\")\n",
    "\n",
    "# 4. 获取所有训练图像的文件路径\n",
    "image_paths = glob.glob(os.path.join(TRAIN_IMAGE_DIR, '*.jpg'))\n",
    "image_paths.extend(glob.glob(os.path.join(TRAIN_IMAGE_DIR, '*.png')))\n",
    "\n",
    "num_images = len(image_paths)\n",
    "if num_images == 0:\n",
    "    print(\"!!! 警告：在文件夹中没有找到 .jpg 或 .png 图像。请检查你的数据。\")\n",
    "else:\n",
    "    print(f\"Total training images found: {num_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0bbde63-10c3-4c8f-a950-69e110e261f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT detector created.\n",
      "Starting SIFT feature extraction... (这可能需要几分钟)\n",
      "Processed 100/11502 images...\n",
      "Processed 200/11502 images...\n",
      "Processed 300/11502 images...\n",
      "Processed 400/11502 images...\n",
      "Processed 500/11502 images...\n",
      "Processed 600/11502 images...\n",
      "Processed 700/11502 images...\n",
      "Processed 800/11502 images...\n",
      "Processed 900/11502 images...\n",
      "Processed 1000/11502 images...\n",
      "Processed 1100/11502 images...\n",
      "Processed 1200/11502 images...\n",
      "Processed 1300/11502 images...\n",
      "Processed 1400/11502 images...\n",
      "Processed 1500/11502 images...\n",
      "Processed 1600/11502 images...\n",
      "Processed 1700/11502 images...\n",
      "Processed 1800/11502 images...\n",
      "Processed 1900/11502 images...\n",
      "Processed 2000/11502 images...\n",
      "Processed 2100/11502 images...\n",
      "Processed 2200/11502 images...\n",
      "Processed 2300/11502 images...\n",
      "Processed 2400/11502 images...\n",
      "Processed 2500/11502 images...\n",
      "Processed 2600/11502 images...\n",
      "Processed 2700/11502 images...\n",
      "Processed 2800/11502 images...\n",
      "Processed 2900/11502 images...\n",
      "Processed 3000/11502 images...\n",
      "Processed 3100/11502 images...\n",
      "Processed 3200/11502 images...\n",
      "Processed 3300/11502 images...\n",
      "Processed 3400/11502 images...\n",
      "Processed 3500/11502 images...\n",
      "Processed 3600/11502 images...\n",
      "Processed 3700/11502 images...\n",
      "Processed 3800/11502 images...\n",
      "Processed 3900/11502 images...\n",
      "Processed 4000/11502 images...\n",
      "Processed 4100/11502 images...\n",
      "Processed 4200/11502 images...\n",
      "Processed 4300/11502 images...\n",
      "Processed 4400/11502 images...\n",
      "Processed 4500/11502 images...\n",
      "Processed 4600/11502 images...\n",
      "Processed 4700/11502 images...\n",
      "Processed 4800/11502 images...\n",
      "Processed 4900/11502 images...\n",
      "Processed 5000/11502 images...\n",
      "Processed 5100/11502 images...\n",
      "Processed 5200/11502 images...\n",
      "Processed 5300/11502 images...\n",
      "Processed 5400/11502 images...\n",
      "Processed 5500/11502 images...\n",
      "Processed 5600/11502 images...\n",
      "Processed 5700/11502 images...\n",
      "Processed 5800/11502 images...\n",
      "Processed 5900/11502 images...\n",
      "Processed 6000/11502 images...\n",
      "Processed 6100/11502 images...\n",
      "Processed 6200/11502 images...\n",
      "Processed 6300/11502 images...\n",
      "Processed 6400/11502 images...\n",
      "Processed 6500/11502 images...\n",
      "Processed 6600/11502 images...\n",
      "Processed 6700/11502 images...\n",
      "Processed 6800/11502 images...\n",
      "Processed 6900/11502 images...\n",
      "Processed 7000/11502 images...\n",
      "Processed 7100/11502 images...\n",
      "Processed 7200/11502 images...\n",
      "Processed 7300/11502 images...\n",
      "Processed 7400/11502 images...\n",
      "Processed 7500/11502 images...\n",
      "Processed 7600/11502 images...\n",
      "Processed 7700/11502 images...\n",
      "Processed 7800/11502 images...\n",
      "Processed 7900/11502 images...\n",
      "Processed 8000/11502 images...\n",
      "Processed 8100/11502 images...\n",
      "Processed 8200/11502 images...\n",
      "Processed 8300/11502 images...\n",
      "Processed 8400/11502 images...\n",
      "Processed 8500/11502 images...\n",
      "Processed 8600/11502 images...\n",
      "Processed 8700/11502 images...\n",
      "Processed 8800/11502 images...\n",
      "Processed 8900/11502 images...\n",
      "Processed 9000/11502 images...\n",
      "Processed 9100/11502 images...\n",
      "Processed 9200/11502 images...\n",
      "Processed 9300/11502 images...\n",
      "Processed 9400/11502 images...\n",
      "Processed 9500/11502 images...\n",
      "Processed 9600/11502 images...\n",
      "Processed 9700/11502 images...\n",
      "Processed 9800/11502 images...\n",
      "Processed 9900/11502 images...\n",
      "Processed 10000/11502 images...\n",
      "Processed 10100/11502 images...\n",
      "Processed 10200/11502 images...\n",
      "Processed 10300/11502 images...\n",
      "Processed 10400/11502 images...\n",
      "Processed 10500/11502 images...\n",
      "Processed 10600/11502 images...\n",
      "Processed 10700/11502 images...\n",
      "Processed 10800/11502 images...\n",
      "Processed 10900/11502 images...\n",
      "Processed 11000/11502 images...\n",
      "Processed 11100/11502 images...\n",
      "Processed 11200/11502 images...\n",
      "Processed 11300/11502 images...\n",
      "Processed 11400/11502 images...\n",
      "Processed 11500/11502 images...\n",
      "Processed 11502/11502 images...\n",
      "...Feature extraction complete.\n",
      "Total images with features: 11502\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建 SIFT 对象\n",
    "sift = cv2.SIFT_create() \n",
    "print(\"SIFT detector created.\")\n",
    "\n",
    "# 2. 创建一个空列表，用来存放所有图像的 SIFT 描述符\n",
    "all_descriptors_list = []\n",
    "\n",
    "print(\"Starting SIFT feature extraction... (这可能需要几分钟)\")\n",
    "\n",
    "# 3. 遍历你找到的每一张图像路径\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    \n",
    "    # 4. 读取图像\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not read image {img_path}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # 5. 转换为灰度图\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # [cite_start]6. 检测关键点并计算描述符 (descriptors) [cite: 6546-6547, 6554]\n",
    "    kp, des = sift.detectAndCompute(gray_img, None)\n",
    "    \n",
    "    # 7. 检查是否找到了特征\n",
    "    if des is not None:\n",
    "        # 8. 如果找到了，把这张图的描述符添加到我们的总列表中\n",
    "        all_descriptors_list.append(des)\n",
    "        \n",
    "    # 打印进度\n",
    "    if (i + 1) % 100 == 0 or (i + 1) == num_images:\n",
    "        print(f\"Processed {i + 1}/{num_images} images...\")\n",
    "\n",
    "print(\"...Feature extraction complete.\")\n",
    "print(f\"Total images with features: {len(all_descriptors_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b027ad-6223-4928-bc02-86ad68e8a903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidating all descriptors into one array...\n",
      "Shape of final descriptors array: (15913117, 128)\n",
      "(This means 15913117 total features found across all images)\n",
      "All SIFT descriptors saved to: E:\\comp9517_project\\COMP9517\\models\\sift_all_train_descriptors.npy\n",
      "=======================\n",
      "✅ Task 1.1 COMPLETED.\n",
      "=======================\n",
      "\n",
      "下一步: 把 ../models/sift_all_train_descriptors.npy 这个文件发给 William，他要用它来跑 K-Means。\n"
     ]
    }
   ],
   "source": [
    "# 1. 使用 numpy 的 vstack (vertical stack) 功能将所有描述符数组垂直堆叠\n",
    "print(\"Consolidating all descriptors into one array...\")\n",
    "all_descriptors = np.vstack(all_descriptors_list)\n",
    "\n",
    "print(f\"Shape of final descriptors array: {all_descriptors.shape}\")\n",
    "print(f\"(This means {all_descriptors.shape[0]} total features found across all images)\")\n",
    "\n",
    "# 2. 定义一个输出路径，用来保存这个大文件\n",
    "#    我们把它保存在 'models' 文件夹里\n",
    "OUTPUT_DIR = '../models/' # 返回上一级，进入 models 文件夹\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR) # 如果 models 文件夹不存在，就创建它\n",
    "\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'sift_all_train_descriptors.npy') \n",
    "\n",
    "# 3. 使用 numpy.save 保存\n",
    "np.save(OUTPUT_FILE, all_descriptors)\n",
    "\n",
    "print(f\"All SIFT descriptors saved to: {os.path.abspath(OUTPUT_FILE)}\")\n",
    "print(\"=======================\")\n",
    "print(\"✅ Task 1.1 COMPLETED.\")\n",
    "print(\"=======================\")\n",
    "print(f\"\\n下一步: 把 {OUTPUT_FILE} 这个文件发给 William，他要用它来跑 K-Means。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508c916-4ce0-4754-9957-8f43a5c449e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
